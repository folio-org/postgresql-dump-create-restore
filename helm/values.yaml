psql:
  jenkinsDbBackupName: "default-backup-name.psql"
  projectNamespace: ""
  clusterName: ""
  job:
    action: "backup" # There is 2 values, "backup" and "restore"
    backoffLimit: "0"
    ttlSecondsAfterFinished: "10"
    activeDeadlineSeconds: "3600"
    initContainer:
      name: "init-chmod-data"
      image:
        repository: "bitnami/bitnami-shell"
        pullPolicy: Always
        tag: "10-debian-10-r327"
      resources:
        limits:
          cpu: "400m"
          memory: "512Mi"
        requests:
          cpu: "80m"
          memory: "400Mi"
      postgresUserGroupId: "1001:1001"
      # Postgres User:GroupID that needs to have access to mounted volume, so, we grant the permissions using init container
    container:
      image:
        repository: "docker-folio.dev.folio.org/org/folio/psql-dump-helm"
        pullPolicy: Always
        tag: "${chartVersion}"
      # The below secret provided with every project deployment and give us such env variables:
      # RANCHER_CLUSTER_PROJECT_NAME, AWS_BUCKET, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY that we use to do aws s3 cp operation
      ##
      s3CredentialsSecret: "s3-postgres-backups-credentials"

      # The below secret provided with every project deployment and give us such env variables:
      # DB_HOST(postgres url of pod in cluster), DB_USERNAME, DB_PASSWORD, DB_DATABASE(db name)
      ##
      dbCredentialsSecret: "db-connect-modules"

      volumeName: "psql-backup-data"
      mountPath: "/mnt/ebs-volume"
      restartPolicy: "Never"
      command: "'/bin/bash', '/pg_dump_restore.sh'"
      resources:
        limits:
          cpu: "800m"
          memory: "250Mi"
        requests:
          cpu: "500m"
          memory: "150Mi"
  pvc:
    name: "psql-backup-volume"
    storageClassName: "gp2"
    storageSize: "10Gi"

nameOverride: ""
fullnameOverride: ""